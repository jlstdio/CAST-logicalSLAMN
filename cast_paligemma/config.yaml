# PaliGemma CAST Training Configuration

# Model Configuration
model:
  name: "google/paligemma-3b-mix-224"
  image_size: [224, 224]
  max_text_length: 128
  
# Action Tokenization
action:
  vocab_size: 256
  num_steps: 8  # 8 steps * 2D = 16 tokens
  action_bounds: [-3.0, 3.0]  # Bounds for normalized actions
  
# Dataset Configuration  
data:
  dataset_name: "catglossop/CAST-dataset"
  train_split: "train"
  val_split: "validation"
  test_split: "test"
  cache_dir: "./cache"
  num_workers: 4
  # Alternative: specify local data directory with TAR files
  local_data_dir: null  # Set to path containing TAR files if HF dataset fails
  
# Training Configuration
training:
  batch_size: 8
  learning_rate: 1e-5
  num_epochs: 10
  warmup_steps: 500
  weight_decay: 0.01
  gradient_accumulation_steps: 4
  max_grad_norm: 1.0
  save_steps: 1000
  eval_steps: 500
  logging_steps: 100
  
# Optimizer Configuration
optimizer:
  name: "adamw"
  betas: [0.9, 0.999]
  eps: 1e-8
  
# Scheduler Configuration  
scheduler:
  name: "linear"
  warmup_ratio: 0.1
  
# Output Configuration
output:
  output_dir: "./checkpoints"
  logging_dir: "./logs"
  run_name: "paligemma-cast"
  save_total_limit: 3
  
# Evaluation Configuration
evaluation:
  eval_batch_size: 16
  save_predictions: true
  compute_metrics: true
  
# Inference Configuration
inference:
  checkpoint_path: "./checkpoints/best_model"
  output_csv: "./results/predictions.csv"
  output_images_dir: "./results/images"
  test_split: "test"
  batch_size: 32

# Hardware Configuration
hardware:
  device: "cuda"
  mixed_precision: true
  dataloader_pin_memory: true